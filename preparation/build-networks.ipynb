{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..', 'module'))\n",
    "import wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get index of articles\n",
    "\n",
    "* [all indices on Wikipedia](https://en.wikipedia.org/wiki/Portal:Contents/Indices)\n",
    "* topics not searched\n",
    "* international trade (\"topics\"), theory of constraints (small)\n",
    "* too big: mathematics, neuroscience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_base = '/Users/harangju/Developer/data/wiki/dumps/'\n",
    "name_xml = 'enwiki-20190801-pages-articles-multistream.xml.bz2'\n",
    "name_index = 'enwiki-20190801-pages-articles-multistream-index.txt.bz2'\n",
    "path_xml = path_base + name_xml\n",
    "path_index = path_base + name_index\n",
    "dump = wiki.Dump(path_xml, path_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# natural & physical sciences\n",
    "topics = ['anatomy', 'biochemistry', 'cognitive science', 'evolutionary biology',\n",
    "          'genetics', 'immunology', 'molecular biology']\n",
    "topics += ['chemistry', 'biophysics', 'energy', 'optics', \n",
    "           'earth science', 'geology', 'meteorology']\n",
    "# philosophy\n",
    "# topics += []\n",
    "topics += ['philosophy of language', 'philosophy of law', \n",
    "           'philosophy of mind', 'philosophy of science']\n",
    "# social sciences\n",
    "topics += ['economics', 'accounting', 'education', 'linguistics', 'law', 'psychology',\n",
    "           'sociology']\n",
    "# technology & applied sciences\n",
    "topics += ['electronics', 'software engineering', 'robotics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "links = {}\n",
    "for topic in topics:\n",
    "    dump.load_page('Index of %s articles' % topic)\n",
    "    links[topic] = [str(l) for l in dump.article_links]\n",
    "    print('Topic \"' + topic + '\" has ' + str(len(links[topic])) + ' articles.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Lists_of_mathematics_topics\n",
    "# algebra\n",
    "math_topics = ['calculus', 'geometry', 'abstract algebra',\n",
    "               'Boolean algebra', 'commutative algebra',# 'homological algebra',\n",
    "               'group theory',# 'representation theory', \n",
    "               'linear algebra']\n",
    "# calculus & analysis\n",
    "# math_topics += ['complex analysis', 'functional analysis',\n",
    "#                 'integration and measure theory', 'harmonic analysis',\n",
    "#                 'Fourier analysis', 'multivariable calculus', 'real analysis',\n",
    "#                 'variational']\n",
    "# geometry\n",
    "# math_topics += ['geometry', 'curves', 'triangle', 'circle', 'general topology',\n",
    "#                 'differential geometry', 'algebraic geometry', 'algebraic topology',\n",
    "#                 'geometric topology', 'know theory', 'Lie groups']\n",
    "# number theory\n",
    "math_topics += [#'algebraic number theory',\n",
    "                'number theory']\n",
    "# applied math\n",
    "math_topics += ['dynamical systems and differential equations']\n",
    "#                 'partial differential equation']\n",
    "topics += math_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "links = {}\n",
    "for topic in math_topics:\n",
    "    dump.load_page(f\"List of {topic} topics\")\n",
    "    links[topic] = [str(l) for l in dump.article_links]\n",
    "    print('Topic \"' + topic + '\" has ' + str(len(links[topic])) + ' articles.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics += ['physics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "topic = 'physics'\n",
    "links[topic] = []\n",
    "for letter in ['!$@', '0–9'] + list(string.ascii_uppercase):\n",
    "    dump.load_page('Index of physics articles (%s)' % letter)\n",
    "    links[topic].extend([str(l) for l in dump.article_links])\n",
    "print('Topic \"' + topic + '\" has ' + str(len(links[topic])) + ' articles.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics += ['mathematics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic = 'mathematics'\n",
    "links[topic] = []\n",
    "for letter in ['0–9'] + list(string.ascii_uppercase):\n",
    "    dump.load_page(\n",
    "        f\"Wikipedia:WikiProject Mathematics/List of mathematics articles ({letter})'\n",
    "    )\n",
    "    links[topic].extend([str(l) for l in dump.article_links])\n",
    "print('Topic \"' + topic + '\" has ' + str(len(links[topic])) + ' articles.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build graphs of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim.utils as gu\n",
    "\n",
    "path_models = '/Users/harangju/Developer/data/wiki/models/'\n",
    "tfidf = gu.SaveLoad.load(path_models + 'tfidf.model')\n",
    "dct = pickle.load(open(path_models + 'dict.model','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One network per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    ls = links[topic]\n",
    "    print('\\nTopic: ' + topic)\n",
    "    networks[topic] = wiki.Net()\n",
    "    networks[topic].build_graph(\n",
    "        name=topic, dump=dump, nodes=ls, model=tfidf, dct=dct\n",
    "    )\n",
    "    networks[topic].save_graph(path + topic + '.pickle')\n",
    "    networks[topic].save_graph(path + topic + '.gexf')\n",
    "    networks[topic].save_barcodes(path + topic + '.barcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net(\n",
    "        path_graph=os.path.join(path_saved, topic+'.pickle'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/harangju/Developer/data/wiki/graphs/barcode/'\n",
    "\n",
    "for topic in topics:\n",
    "    print('\\nTopic: ' + topic)\n",
    "    networks[topic].save_barcodes(os.path.join(path, topic+'.barcode'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subnetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_links = list(set([v for l in links.values() for v in l]))\n",
    "len(all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "\n",
    "big_network = wiki.Net()\n",
    "big_network.build_graph(\n",
    "    name='big_network',\n",
    "    dump=dump, \n",
    "    nodes=all_links, \n",
    "    model=tfidf, \n",
    "    dct=dct,\n",
    "    compute_core_periphery=False, \n",
    "    compute_communities=False, \n",
    "    compute_community_cores=False\n",
    ")\n",
    "big_network.save_graph(os.path.join(path, 'big_network_physics_math.pickle'))\n",
    "big_network.save_graph(os.path.join(path, 'big_network_physics_math.gexf'))\n",
    "# big_network.save_barcodes(os.path.join(path, 'big_network.barcode'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes without years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/harangju/Developer/data/wiki/graphs/dated-noyear/'\n",
    "\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "networks_noyear = {}\n",
    "for topic in topics:\n",
    "    print('\\nTopic: ' + topic)\n",
    "    networks_noyear[topic] = wiki.Net()\n",
    "    networks_noyear[topic].build_graph(\n",
    "        name=topic, dump=dump, nodes=links[topic],\n",
    "        fill_empty_years=False,\n",
    "        compute_core_periphery=False,\n",
    "        compute_communities=False,\n",
    "        compute_community_cores=False\n",
    "    )\n",
    "    networks_noyear[topic].save_graph(path + topic + '.pickle')\n",
    "    networks_noyear[topic].save_graph(path + topic + '.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/harangju/Developer/data/wiki/graphs/dated-noyear/'\n",
    "\n",
    "networks_noyear = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks_noyear[topic] = wiki.Net()\n",
    "    networks_noyear[topic].load_graph(path + topic + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "\n",
    "fraction_years = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            topic,\n",
    "            len([\n",
    "                y\n",
    "                for n, y in nx.get_node_attributes(\n",
    "                    networks_noyear[topic].graph, 'year'\n",
    "                ).items()\n",
    "                if y\n",
    "            ]) / len(networks_noyear[topic].graph.nodes)\n",
    "        ]\n",
    "        for topic in topics\n",
    "    ],\n",
    "    columns=['topics', 'fraction']\n",
    ")\n",
    "fraction_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for topic in topics:\n",
    "#     print(topic, end='\\t')\n",
    "#     print( \n",
    "#         len([\n",
    "#             y\n",
    "#             for n, y in nx.get_node_attributes(\n",
    "#                 networks_noyear[topic].graph, 'year'\n",
    "#             ).items()\n",
    "#             if y\n",
    "#         ]) / len(networks_noyear[topic].graph.nodes)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_fig = '/Users/harangju/Library/Mobile Documents/com~apple~CloudDocs/' +\\\n",
    "    'Documents/research/wikipedia/results'\n",
    "path_plot = '0 graphs'\n",
    "\n",
    "fig = px.histogram(fraction_years.fraction)\n",
    "fig.update_layout(\n",
    "    width=500, height=360,\n",
    "    template='plotly_white',\n",
    "    xaxis={'range': [0, 1]},\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(path_fig, path_plot, 'fraction_years_with_math.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate null networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net()\n",
    "    networks[topic].load_graph(path_saved + topic + '.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized target & year\n",
    "\n",
    "Just randomizing year -> you get the same structures, it's just a matter of when you get those structures.\n",
    "If you randomize year & target, then you're randomizing the structure & how they come about without changing any basic network statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "null_models = ['target', 'year']\n",
    "num_nulls = 10\n",
    "nulls = {}\n",
    "for null_model in null_models:\n",
    "    print('Null model: ' + null_model)\n",
    "    path_to_save_null = '/Users/harangju/Developer/data/wiki/graphs/null-'\\\n",
    "                        +null_model+'/'\n",
    "    nulls[null_model] = {}\n",
    "    for topic, network in networks.items():\n",
    "        print('Topic: ' + topic)\n",
    "        nulls[null_model][topic] = []\n",
    "        for i in range(num_nulls):\n",
    "            print('Null: ' + str(i))\n",
    "            null = network.randomize(null_model)\n",
    "            null.graph.name = topic+'-null-'+str(i)\n",
    "            null.save_graph(path_to_save_null + null.graph.name + '.pickle')\n",
    "            null.save_barcodes(path_to_save_null + null.graph.name + '.barcode')\n",
    "            nulls[null_model][topic].append(null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jittered years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_jitters = 1\n",
    "max_jitter = 1\n",
    "null_model = 'jitter'\n",
    "path_to_save_null = '/Users/harangju/Developer/data/wiki/graphs/null-'+null_model+'/'\n",
    "if not os.path.isdir(path_to_save_null):\n",
    "    os.mkdir(path_to_save_null)\n",
    "jittered = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "for topic, network in networks.items():\n",
    "    print('Topic: ' + topic)\n",
    "    jittered[topic] = []\n",
    "    print('Null: ', end='')\n",
    "    for i in range(num_jitters):\n",
    "        print(str(i), end=' ')\n",
    "        null = wiki.Net()\n",
    "        null.graph = copy.deepcopy(network.graph)\n",
    "        for node in null.graph.nodes:\n",
    "            null.graph.nodes[node]['year'] = null.graph.nodes[node]['year'] +\\\n",
    "                np.random.randint(-max_jitter, max_jitter+1)\n",
    "        null.graph.name = topic+'-null-'+str(i)\n",
    "        null.save_graph(path_to_save_null + null.graph.name + '.pickle')\n",
    "        null.save_barcodes(path_to_save_null + null.graph.name + '.barcode')\n",
    "        jittered[topic].append(null)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gephi notes\n",
    "* node size, fruchterman reingold = [10, 40], force atlas 2 = [4 16]\n",
    "* text size = [1 1.4]\n",
    "* preview font size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative networks\n",
    "* random geometric graph (modularity)\n",
    "* stochastic block model (modularity)\n",
    "* caveman graph (modularity, cliques, most clustered & sparse)\n",
    "* random clustered graph (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_nulls = 10\n",
    "gen_functions = {\n",
    "    'rgg': lambda g: nx.random_geometric_graph(\n",
    "        g.number_of_nodes(), \n",
    "    ),\n",
    "    'sbm': lambda g: nx.stochastic_block_model(\n",
    "        \n",
    "    ),\n",
    "    'cg': lambda g: nx.caveman_graph(\n",
    "        \n",
    "    ),\n",
    "    'rcg': lambda g: nx.random_clustered_graph(\n",
    "        \n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_nulls = 10\n",
    "gen_nulls = {}\n",
    "for name, function in gen_functions.items():\n",
    "    print('Null model: ' + null_model)\n",
    "    path_to_save_null = '/Users/harangju/Developer/data/wiki/graphs/null-'+\\\n",
    "        null_model+'/'\n",
    "    nulls[null_model] = {}\n",
    "    for topic, network in networks.items():\n",
    "        print('Topic: ' + topic)\n",
    "        nulls[null_model][topic] = []\n",
    "        for i in range(num_nulls):\n",
    "            print('Null: ' + str(i))\n",
    "            null = network.randomize(null_model)\n",
    "            null.graph.name = topic+'-null-'+str(i)\n",
    "            null.save_graph(path_to_save_null + null.graph.name + '.pickle')\n",
    "            null.save_barcodes(path_to_save_null + null.graph.name + '.barcode')\n",
    "            nulls[null_model][topic].append(null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate networks for D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net()\n",
    "    networks[topic].load_graph(path_saved + topic + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(topic, len(networks[topic].graph.nodes)) for topic in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json as js\n",
    "import networkx as nx\n",
    "\n",
    "path = '/Users/harangju/Developer/data/wiki/graphs/json/'\n",
    "\n",
    "for topic, network in networks.items():\n",
    "    nodes = sorted(network.graph.nodes, key=lambda n: network.graph.nodes[n]['year'])\n",
    "    json = js.dumps({\n",
    "        'nodes': [\n",
    "            {\n",
    "                'id': node,\n",
    "                'year': int(network.graph.nodes[node]['year']),\n",
    "#                 'core_be': int(network.graph.nodes[node]['core_be']),\n",
    "#                 'core_rb': network.graph.nodes[node]['core_rb'],\n",
    "                'community': int(network.graph.nodes[node]['community']),\n",
    "                'degree': network.graph.degree(node)\n",
    "            }\n",
    "            for i, node in enumerate(nodes)\n",
    "        ],\n",
    "        'links': [\n",
    "            {\n",
    "                'source': i,\n",
    "                'target': nodes.index(target),\n",
    "                'weight': network.graph.edges[node, target]['weight']\n",
    "            }\n",
    "            for i, node in enumerate(nodes)\n",
    "            for target in network.graph.successors(node)\n",
    "        ]\n",
    "    })\n",
    "    with open(os.path.join(path, topic+'.json'), 'w') as file:\n",
    "        file.write(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate barcodes for D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_saved = '/Users/harangju/Developer/data/wiki/graphs/dated/'\n",
    "networks = {}\n",
    "for topic in topics:\n",
    "    print(topic, end=' ')\n",
    "    networks[topic] = wiki.Net(\n",
    "        path_graph=os.path.join(path_saved, topic+'.pickle'),\n",
    "#         path_barcodes=os.path.join(path_saved, topic+'.barcode')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = networks['cognitive science'].filtration\n",
    "m = networks['cognitive science'].persistence\n",
    "for i, c in enumerate(m):\n",
    "    if m.pair(i) < i: continue      # skip negative simplices\n",
    "    dim = f[i].dimension()\n",
    "    if m.pair(i) != m.unpaired:\n",
    "        print(f\"{i}, {dim}, {c}, {m[i]}, {m.pair(i)}, {m[m.pair(i)]}\")\n",
    "    else:\n",
    "        print(f\"{i}, {dim}, {c}, {m[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m[m.pair(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dionysus as d\n",
    "\n",
    "dgms = d.init_diagrams(\n",
    "    networks['earth science'].persistence,\n",
    "    networks['earth science'].filtration\n",
    ")\n",
    "dgms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, dgm in enumerate(dgms):\n",
    "    print(f\"dim {i}\", end=' ')\n",
    "    for p in dgm:\n",
    "        print(p, end='; ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dgms[2][0], dgms[2][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "barcodes = networks['cognitive science'].barcodes.copy()\n",
    "barcodes = barcodes\\\n",
    "    .drop(index=barcodes[barcodes.lifetime==0].index)\\\n",
    "    .reset_index(drop=True)\n",
    "barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "barcodes.iloc[27]['death simplex'], barcodes.iloc[27]['homology nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/harangju/Developer/data/wiki/graphs/barcode csv/'\n",
    "\n",
    "for topic, network in {'cognitive science': networks['cognitive science']}.items(): #networks.items():\n",
    "    barcodes = network.barcodes.copy(deep=True)\n",
    "    barcodes = barcodes\\\n",
    "        .drop(index=barcodes[barcodes.lifetime==0].index)\\\n",
    "        .reset_index(drop=True)\n",
    "    barcodes.death = barcodes.death\\\n",
    "        .replace(np.inf, 2100)\\\n",
    "        .astype(int)\n",
    "    csv = 'i,birth,death,dim,cavity,death_nodes\\n'\n",
    "    for i, row in barcodes.iterrows():\n",
    "        if row.lifetime==np.inf:\n",
    "            cavity = row['birth simplex']\n",
    "        else:\n",
    "            cavity = row['homology nodes']\n",
    "        csv += f\"{i},{row.birth},{row.death},{row.dim},{';'.join(cavity)},\" + \\\n",
    "            f\"{';'.join(row['death nodes'])}\\n\"\n",
    "    with open(os.path.join(path, topic+'.csv'), 'w') as file:\n",
    "        file.write(csv)\n",
    "# print(csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
